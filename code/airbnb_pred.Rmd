---
title: "Airbnb Pricing in Shanghai / China"
subtitle: "Data Analysis 3 - Assignment 2"
author: "Ersan Kucukoglu"
output:
  html_document:
    code_download: true
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

```{r, include=FALSE}
# initialize packages -------------------------------------------------------------------
library(tidyverse)
library(skimr)
library(Hmisc)
library(cowplot)
library(data.table)
library(rattle)
library(caret)
library(ranger)
library(knitr)
library(kableExtra)
library(xtable)
library(rpart)
library(pdp)
library(scales)

```

## Introduction

This assignment focuses on a single location - Shanghai, China - and seeks to estimate AirBnB rental costs per night for a firm renting small and mid-size flats (2-6 guests) to assist them in pricing their properties that are not yet on the market.

## Data

The used dataset was downloaded from [insideairbnb.com](http://insideairbnb.com/get-the-data.html) which is a site collecting data on AirBnB listings in numerous cities. As mentioned above the dataset contains data on listings in Shanghai and was last updated on 24th December 2021.

### Cleaning

Some data cleaning was required to make the dataset viable for prediction applications. There were 29165 observations and 74 variables in the raw dataset. Some of these variables, such as urls and textual descriptions, were removed since the data contained in them could not be utilised by the deployed prediction models. Data types have to be adjusted since some numeric and date variables were saved as characters. There was another one variable, amenities, which recorded various listing attributes and extras in a list style. This variable was initially divided into independent dummy variables, and then comparable ones, such as wifi with varied speeds, grouped together.At the end of the operation, the grouping produced 9 dummy variables. The full dataset was filtered to only contain listings that are complete apartments and can accommodate 2-6 guests, and factors were created from qualitative variables with multiple categories. This implies that the data contains three categories of apartments: rental units, lofts, and serviced apartments.


```{r, include=FALSE, cache=TRUE}
# Load data
gz <- gzfile('~/Desktop/BA-Courses/Data_Analysis3/Assignment2/data/raw/shanghai.csv.gz','rt') 
listings <- read.csv( gz, header = T )

# keep apartments which can host 2-6 guests
data <- listings %>% filter( accommodates %in% c(2:6) )

# check property_type variable
table(data$property_type)

# keep if property_type suggests that the place is an apartment
data <- data %>% 
  filter( property_type %in% c('Entire loft', 'Entire serviced apartment','Entire rental unit') )


### filter variables which cannot be used for prediction in this task
data <- data %>% select( -c( listing_url, scrape_id, description, neighborhood_overview, 
                                   picture_url, host_url, host_name, host_location, host_about,
                                   host_thumbnail_url, host_picture_url, host_neighbourhood, 
                                   host_listings_count, neighbourhood_group_cleansed, bathrooms, 
                                  minimum_minimum_nights, minimum_maximum_nights, 
                                   minimum_nights_avg_ntm, maximum_minimum_nights, 
                                   maximum_maximum_nights, maximum_nights_avg_ntm, calendar_updated, 
                                   has_availability, availability_30, availability_60, availability_90, availability_365, 
                                   calendar_last_scraped, number_of_reviews_ltm, number_of_reviews_l30d, license ) )
glimpse(data)

### convert price variable to numeric
# remove $ sign and comma
data$price <- as.numeric(gsub("[\\$,]","",data$price))

names(data)[names(data) == "bathrooms_text"] <- "bathrooms"
# Remove text from bathrooms column
table(data$bathrooms)
data$bathrooms <- gsub("baths", "", data$bathrooms)
data$bathrooms <- gsub("bath", "", data$bathrooms)
data$bathrooms <- replace(data$bathrooms,data$bathrooms == 'Half-',0.5)
data$bathrooms <- as.numeric(data$bathrooms)

# replace 'NA' string with NA
data$bathrooms <- ifelse( data$bathrooms == 'NA', NA, as.numeric( data$bathrooms ) )

# replace 'N/A' string with NA
data$host_response_rate <- ifelse( data$host_response_rate == 'N/A', NA, data$host_response_rate )

# remove % sign and convert to numeric
data$host_response_rate <- as.numeric( gsub( "%","",data$host_response_rate ) )

### convert host_acceptance_rate variable to numeric
data$host_acceptance_rate <- ifelse( data$host_acceptance_rate == 'N/A', NA, data$host_acceptance_rate )

# remove % sign and convert to numeric
data$host_acceptance_rate <- as.numeric( gsub( "%","",data$host_acceptance_rate ) )

### extract amenities
# remove unnecessary signs and convert to list
data$amenities <- tolower( data$amenities )
data$amenities <- gsub("\\[","", data$amenities)
data$amenities <- gsub("\\]","", data$amenities)
data$amenities <- gsub('\\"',"",data$amenities)
data$amenities <- as.list(strsplit(data$amenities, ","))

# define levels and dummies and append to data
levels <- levels(factor(unlist(data$amenities)))
data <- cbind(data,as.data.frame(do.call(rbind, lapply(lapply(data$amenities, factor, levels), table))))


### convert date columns to date
data$first_review <- as.Date( data$first_review, format="%Y-%m-%d" )

data$last_review <- as.Date( data$last_review, format="%Y-%m-%d" )

data$host_since <- as.Date( data$host_since, format="%Y-%m-%d" )

# function to aggregate several columns of same type/category into one generic binary column
aggregate_columns <- function(word){
  
  # subset columns which contain a specific word and save them to another dataframe, also select 'id' to use for merge later
  new_df <- data %>% select(contains(word),"id")
  
  # go row by row to see if any of the rows have a 1, if it does, populate new column 'col_name' with 1
  new_df$col_name <- apply(new_df[0:ncol(new_df)], 1, function(x) ifelse(any(x == 1), '1', '0'))
  
  # save new column and id column to another dataframe, this new dataframe is used to merge with original dataframe
  new_df_merge <- new_df %>% select(id,col_name)
  
  # merge original dataframe and new_df_merge by 'id'
  data <- merge(data,new_df_merge,by = "id", all = FALSE)
  
  # remove the new column and 'id' column from the new_df dataframe
  new_df <- new_df %>% select(-c(id,col_name))
  
  # remove the selected columns from original dataframe since they have already been aggregated into a new column and merged
  data <<- data %>% select(-colnames(new_df))
}

# aggregate columns for a few amenities that could be important for predicting price
aggregate_columns("refrigerator")
data <- data %>% rename("refrigerator" = col_name)

aggregate_columns("tv")
data <- data %>% rename("tv" = col_name)

aggregate_columns("wifi")
data <- data %>% rename("wifi" = col_name)

aggregate_columns("baby")
data <- data %>% rename("baby" = col_name)

aggregate_columns("stove")
data <- data %>% rename("stove" = col_name)

aggregate_columns("air conditioning")
data <- data %>% rename("air_conditioning" = col_name)

aggregate_columns("microwave")
data <- data %>% rename("microwave" = col_name)

aggregate_columns("free parking")
data <- data %>% rename("free_parking" = col_name)

aggregate_columns("paid parking")
data <- data %>% rename("paid_parking" = col_name)

# drop the amenities column because a csv cannot store it since it is a list
data <- data %>% select( -amenities )

# drop amenities that were not used
data <- data[ -c( 43:238 )]

# convert property_type to factor
data <- data %>%
  mutate(f_property_type = factor(property_type))

# convert neighbourhood_cleansed to factor

data <- data %>% separate(neighbourhood_cleansed , " / " ,
                into = c("garbage","neighbourhood_cleansed") )

data <- data %>% 
  mutate( f_neighbourhood = factor(neighbourhood_cleansed))

# add new numeric columns from certain columns
numericals <- c("host_response_rate", "host_acceptance_rate", "host_total_listings_count", "accommodates", "bedrooms", "beds", "number_of_reviews", "review_scores_rating", "calculated_host_listings_count", "reviews_per_month", "bathrooms")                                 

data <- data %>%
  mutate_at(vars(numericals), funs("n"=as.numeric))


# rename columns so they start with n_ as opposed to end with _n
nnames <- data %>%
  select(ends_with("_n")) %>%
  names()
nnames_i <- match(nnames, colnames(data))
colnames(data)[nnames_i] <- paste0("n_", numericals)

# create days since first review
data <- data %>% mutate(
  n_days_since_rv = as.numeric(as.Date(last_scraped,format="%Y-%m-%d") -
                                 as.Date(first_review ,format="%Y-%m-%d")))

# create dummies ----------------------------------------------------------

# create dummies
data <- data %>% mutate(
  d_superhost = ifelse( host_is_superhost == 't', 1, 0),
  d_profile_pic = ifelse( host_has_profile_pic == 't', 1, 0),
  d_identity_verified = ifelse( host_identity_verified == 't', 1, 0),
  d_instant_bookable = ifelse( instant_bookable == 't', 1, 0)
)

# rename amenities dummies
dummies <- c( "wifi", "tv", "refrigerator", "air_conditioning", "baby", "stove","microwave", "free_parking", "paid_parking" )
data <- data %>%
  mutate_at(vars(dummies), funs("d"= (.)))
# rename columns
dnames <- data %>%
  select(ends_with("_d")) %>%
  names()
dnames_i <- match(dnames, colnames(data))
colnames(data)[dnames_i] <- paste0("d_", tolower(gsub("[^[:alnum:]_]", "",dummies)))

# filter needed variables -------------------------------------------------

# keep columns if they start with d_, n_, f_ and some others
data <- data %>%
  select(matches("^d_.*|^n_.*|^f_.*|^p_.*|^usd_.*"), price, id,
         neighbourhood_cleansed, property_type)
```

## Exploratory Data Analysis
After cleaning, I double-checked the qualities of the variables I intend to use in the prediction models. This necessitated reviewing descriptive data, its distribution, and, in the case of explanatory factors, investigating their association to the target variable - the price per person per night.


```{r, include=FALSE, cache=TRUE}
#### EXPLORATORY DATA ANALYSIS

# label engineering ----------------------------------------
summary(data$price)
describe(data$price)
```

```{r, cache=TRUE}
# summary table for price
price_stat <- data %>% summarise(
  Variable = 'Price',
  Mean     = mean( price ),
  `5th Percentile` = quantile(price, probs = 0.05),
  Median   = median( price ),
  `95th Percentile` = quantile(price, probs = 0.95),
  Std      = sd( price ),
  Min      = min( price ),
  Max      = max( price ),
  N        = n() )

# print 
knitr::kable( price_stat, caption = "Descriptive statistics of target variable", digits = 2 ) %>% kable_styling( position = "center", latex_options = 'hold_position' )
```

After removing the data, I created a histogram for the price variable, which is shown below. Based on the graph, we can state that its distribution is skewed with a large right tail; nevertheless, for simplicity of interpretation, I choose to utilize its levels rather than its logs.

```{r, cache=TRUE}

# Price Distribution
price_hist <- ggplot(data, aes( x = price)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)),fill = "cyan", color = "black") +
  theme_bw() +
  scale_y_continuous(labels = label_percent()) +
  ylab("Percent") + 
  xlab("Price")

# Take log of price
data <- data %>%
  mutate(ln_price = log(price))

# remove extreme values which are way above the 95th percentile
data <- data %>%
  filter(price < 1300)

# histogram for price
ggplot( data = data, aes(price) ) +
  geom_histogram( ) +
  theme_bw() +
  labs( x='\n Price', y='Absolute Frequency \n', title = 'Distribution of Price per Night') +
  theme( panel.grid.minor.x = element_blank(), 
         plot.title = element_text( size = 12, face = "bold", hjust = 0.5 ) )

```

```{r, include=FALSE, cache=TRUE}
# histogram for ln(price)
ggplot( data = data, aes(ln_price) ) +
  geom_histogram() +
  theme_bw() +
  labs( x='\n Ln(Price)', y='Absolute Frequency \n', title = 'Distribution of Ln(Price per Night)') +
  theme( panel.grid.minor.x = element_blank(), 
         plot.title = element_text( size = 12, face = "bold", hjust = 0.5 ) )
```

### Feature engineering

Having decided about the functional form of the target variable I inspected the explanatory variables and their relationship with the target variable. Besides deciding on grouping of factor variables functional forms also had to be decided because two of the used prediction models were OLS and OLS with LASSO for which this step is necessary.

First, I inspected the two factor variables: property type and neighbourhood. The prices conditional on property type can be seen in the chart below. Since there are differences between the three categories in conditional means as well as standard deviation I decided to keep all three.

```{r, cache=TRUE}
# boxplot of price by property type
ggplot(data = data, aes(x = f_property_type, y = price)) +
  stat_boxplot(aes(group = f_property_type), geom = "errorbar", width = 0.3)+
  geom_boxplot(aes(group = f_property_type),
               size = 0.5, width = 0.6, alpha = 0.3, na.rm=T, outlier.shape = NA) +
  labs(x = "Property type",y = "Price", title="Boxplots of price conditional on property type") +
  theme( panel.grid.minor.x = element_blank(), 
         plot.title = element_text( size = 12, face = "bold", hjust = 0.5 ) ) +
  theme_bw()
```

```{r, include=FALSE, cache=TRUE}
# check categorical variables ---------------------------------------------

categoricals <- c("f_property_type", "f_neighbourhood")

for (i in 1:length(categoricals)) {
  data %>%
    group_by(get(categoricals[i])) %>%
    summarise(mean_price = mean(price) ,  n=n()) %>%
    print
}
```

I examined the dummies after the categorical variables. There are 13 in all, 9 of which were formed by separating and grouping the amenities variable, 3 of which are related to host features such as if their identity is confirmed, and 1 of which is linked to the apartment and tells whether it may be booked instantly. I calculated the conditional mean price for each dummy and came to the conclusion that my assumptions were correct in the sense that an apartment with more extras priced more in general.

```{r, include=FALSE, cache=TRUE}
# check dummy variables 

dummies <- c( "d_wifi", "d_tv", "d_refrigerator", "d_air_conditioning", 
              "d_microwave", "d_baby", "d_stove", "d_free_parking", "d_paid_parking",
              "d_superhost", "d_profile_pic", "d_identity_verified", "d_instant_bookable")

for (i in 1:length(dummies)) {
  data %>%
    group_by(get(dummies[i])) %>%
    summarise(mean_price = mean(price) ,  n=n()) %>%
    print
}

```

The number of guests the apartment can accommodate is likely one of the most crucial numerical variables in determining the pricing. The table below shows how the price varies with the number of guests. Despite the wide standard deviation, the prices of apartments that can accommodate more people tend to be higher, and because the association looks linear, I agreed to keep this variable as it is and treat is as a continuous one.

```{r, include=FALSE}
# check numerical variables -----------------------------------------------

### n_accommodates
data %>%
  group_by(n_accommodates) %>%
  summarise(mean_price = mean(price), min_price= min(price), max_price = max(price), n = n())
```

```{r, cache=TRUE}
ggplot(data = data, aes(x=n_accommodates, y=price)) +
  geom_point(size=1, shape=16)+
  ylim(0,900)+
  xlim(2,6)+
  labs(x="Number of accommodates",y="Price", title = "Relationship between number of people accommodated and price")+
  geom_smooth(method="lm",  se=FALSE, color = "red") +
  theme_bw() +
  theme( panel.grid.minor.x = element_blank(), 
         plot.title = element_text( size = 12, face = "bold", hjust = 0.5 ) )

```

I repeated this process for all the other numeric variables as well. If one variable only had a few values then I calculated the conditional mean of price for those and for every variable I examined its relationship with price either by a loess regression or a very simple OLS which contained price as the outcome variable and the variable in question plus its transformed versions. The loess regression showed the pattern of association between the target and the explanatory variable while the OLS helped to confirm if my assumption about the functional form was right.

In the charts below I highlight some of the patterns that I discovered. In the first one we can see that the relationship between the number of beds and price is nonlinear, therefore I created a new variable as the square of the number of beds variable so that I can add it to the OLS and LASSO models later on.

```{r, include=FALSE, cache=TRUE}
### n_beds
data %>%
  group_by(n_beds) %>%
  summarise(mean_price = mean(price), min_price= min(price), max_price = max(price), n = n())

# impute missing and 0 with n_accommodates assume they mean the same
data <- data %>% 
  mutate(n_beds = ifelse(is.na(n_beds), n_accommodates, n_beds),
         n_beds = ifelse( n_beds == 0, n_accommodates, n_beds))
```

```{r, cache=TRUE}
# check the relationship with price
ggplot( data, aes( x = n_beds, y = price ) ) +
  geom_smooth( method = "loess", se=F, color = "red") +
  theme_bw() +
  theme( panel.grid.minor.x = element_blank(), 
         plot.title = element_text( size = 12, face = "bold", hjust = 0.5 ) ) +
  labs( x = "Number of beds", y = "Price", title = "Relationship between number of beds and price")
```

```{r, include=FALSE, cache=TRUE}
# add square of n_beds
data <- data %>% mutate( n_beds2 = n_beds^2)

# regression 1: price and n_beds
reg1<-lm(price ~ n_beds, data=data)
summary(reg1)
# regression 2: price and n_beds + n_beds2
reg2<-lm(price ~ n_beds + n_beds2, data=data)
summary(reg2)

```

```{r, include=FALSE, cache=TRUE}
### n_bathrooms
data %>%
  group_by(n_bathrooms) %>%
  summarise(mean_price = mean(price), min_price= min(price), max_price = max(price), n = n())

ggplot(data, aes(n_bathrooms)) +
  geom_histogram( alpha = 0.8, size = 0.25) +
  ylab("") +
  xlab("N of bathrooms")

# impute missing with median
data <- data %>%
  mutate( n_bathrooms =  ifelse(is.na(n_bathrooms), median(n_bathrooms, na.rm = T), n_bathrooms))

# add log bathrooms to df
data <- data %>% mutate( ln_bathrooms = log(n_bathrooms))

# use log bathrooms in the model
```

Based on the histogram below I could conlcude that the number of reviews has a very skewed distribution therefore I added its log to the dataset and checked whether it gave a better result for the OLS that I ran using price and number of reviews. Since it did produce a better result I decided to use the log transformed version of this variable in the OLS and LASSO models.

```{r, include = FALSE, cache=TRUE}
### n_number of reviews
describe(data$n_number_of_reviews)

# filter the df to check the distribution of number of reviews
nreview_plot <- data %>%
  filter(n_number_of_reviews < 100)
```

```{r, cache=TRUE}
ggplot(nreview_plot, aes(n_number_of_reviews)) +
  geom_histogram(binwidth = 5, alpha = 0.8, size = 0.25, fill= "cyan") +
  theme_bw() +
  theme( panel.grid.minor.x = element_blank(), 
         plot.title = element_text( size = 12, face = "bold", hjust = 0.5 ) ) +
  labs( x = "Number of reviews", y = "Absolute Frequency", title = "Distribution of number of reviews")
```


```{r, include = FALSE, cache=TRUE}
# use logs as well because the distribution is very skewed
data <- data %>% 
  mutate(ln_number_of_reviews = log(n_number_of_reviews+1))

ggplot(data, aes(ln_number_of_reviews)) +
  geom_histogram(binwidth = 0.5, alpha = 0.8, size = 0.25,fill="blue") +
  ylab("") +
  xlab("Log Number of reviews")

# regression 3: price and number of reviews
reg3<-lm(price ~ n_number_of_reviews, data=data)
summary(reg3)
# regression 4: price and log number of reviews
reg4<-lm(price ~ ln_number_of_reviews, data=data)
summary(reg4)

### n_days_since_rv
describe(data$n_days_since_rv)

# check the relationship with price
ggplot( data, aes( x = n_days_since_rv, y = price ) ) +
  geom_smooth( method = "loess", se=F, color = "red") +
  theme_bw()

# add square to df
data <- data %>%
  mutate(
    n_days_since_rv2=n_days_since_rv^2)


### n_review_scores_rating
describe(data$n_review_scores_rating)

# check the relationship with price
ggplot( data, aes( x = n_review_scores_rating, y = price ) ) +
  geom_smooth( method = "loess", se=F, color = "red", size = 1.5 ) +
  theme_bw()


### n_host_acceptance_rate
describe(data$n_host_acceptance_rate)

# check the relationship with price
ggplot( data, aes( x = n_host_acceptance_rate, y = price ) ) +
  geom_smooth( method = "loess", se=F, color = "red", size = 1.5 ) +
  theme_bw()

# add square to df
data <- data %>%
  mutate(
    n_host_acceptance_rate2=n_host_acceptance_rate^2)

### n_host_response_rate
describe(data$n_host_response_rate)

# check the relationship with price
ggplot( data, aes( x = n_host_response_rate, y = price ) ) +
  geom_smooth( method = "loess", se=F, color = "red", size = 1.5 ) +
  theme_bw()

# add square to df
data <- data %>%
  mutate(
    n_host_response_rate2=n_host_response_rate^2)

### n_host_total_listings_count
describe(data$n_host_total_listings_count)

# check the relationship with price
ggplot( data, aes( x = log(n_host_total_listings_count), y = price ) ) +
  geom_smooth( method = "loess", se=F, color = "red", size = 1.5 ) +
  theme_bw()

# add log to df
data <- data %>%
  mutate(
    ln_host_total_listings_count=log(n_host_total_listings_count))

### n_bedrooms
describe(data$n_bedrooms)

# check the relationship with price
ggplot( data, aes( x = n_bedrooms, y = price ) ) +
  geom_smooth( method = "loess", se=F, color = "red", size = 1.5 ) +
  theme_bw()

# add square to df
data <- data %>%
  mutate(
    n_bedrooms2=n_bedrooms^2)


### n_reviews_per_month
describe(data$n_reviews_per_month)

# check the relationship with price
ggplot( data, aes( x = n_reviews_per_month, y = price ) ) +
  geom_smooth( method = "loess", se=F, color = "red", size = 1.5 ) +
  theme_bw()


# change infinite values to NaNs
for (j in 1:ncol(data) ) data.table::set(data, which(is.infinite(data[[j]])), j, NA)
```

I also checked the number of missing values for each of the variables. Fortunately there were no missing values in the target variable so I did not lose observations because of them. As for the explanatory variables I applied the following method:
If the missing values could be substituted in any way by utilizing the values of another variable, I did so. For example, when the number of beds for an apartment was missing, I substituted it with the number of persons accommodated variable because they are likely to be the same.
If the variable had less than 10 missing values that I couldn't impute in the above-mentioned manner, I imputed it using the variable's median.
If the variable had more than 10 missing values but less than 20% of its total value was missing, I performed the same thing as in the second example, plus I added flags to show where I had imputed values.

```{r, include = FALSE, cache=TRUE}
# check missing values ----------------------------------------------------

to_filter <- sapply(data, function(x) sum(is.na(x)))
to_filter[to_filter > 0]


# impute without flags where there are only a few missing
data <- data %>% 
  mutate( n_host_total_listings_count = ifelse(is.na(n_host_total_listings_count), median(n_host_total_listings_count, na.rm = T), n_host_total_listings_count),
          ln_bathrooms = ifelse(is.na(ln_bathrooms), 1, ln_bathrooms),
          n_bedrooms = ifelse(is.na(n_bedrooms),n_beds%/%2, n_bedrooms))

# redo their polinomials and logs
data <- data %>% 
  mutate(ln_host_total_listings_count = log(n_host_total_listings_count+1),
         n_bedrooms2 = n_bedrooms^2)

# impute with flags where there are more missing
data <- data %>%
  mutate(
    flag_days_since_rv=ifelse(is.na(n_days_since_rv),1, 0),
    n_days_since_rv =  ifelse(is.na(n_days_since_rv), median(n_days_since_rv, na.rm = T), n_days_since_rv),
    flag_review_scores_rating=ifelse(is.na(n_review_scores_rating),1, 0),
    n_review_scores_rating =  ifelse(is.na(n_review_scores_rating), median(n_review_scores_rating, na.rm = T), n_review_scores_rating),
    flag_reviews_per_month=ifelse(is.na(n_reviews_per_month),1, 0),
    n_reviews_per_month =  ifelse(is.na(n_reviews_per_month), median(n_reviews_per_month, na.rm = T), n_reviews_per_month),
    flag_number_of_reviews=ifelse(n_number_of_reviews==0,1, 0),
    flag_host_response_rate = ifelse(is.na(n_host_response_rate), 1, 0),
    n_host_response_rate = ifelse(is.na(n_host_response_rate), median(n_host_response_rate, na.rm = T), n_host_response_rate),
    flag_host_acceptance_rate = ifelse(is.na(n_host_acceptance_rate), 1, 0),
    n_host_acceptance_rate = ifelse(is.na(n_host_acceptance_rate), median(n_host_acceptance_rate, na.rm = T), n_host_acceptance_rate)
  )

# redo their polinomials and logs
data <- data %>% mutate(
  n_days_since_rv2 = n_days_since_rv^2,
  n_host_acceptance_rate2 = n_host_acceptance_rate^2,
  n_host_response_rate2 = n_host_response_rate^2
)
```

Lastly, I examined possible interactions between the property type factor variable and all the dummy variables by using plots. I created two lists of interactions: one for OLS and one for LASSO. In the one for OLS I only included those ones where the differences between the different categories of variables were indeed very big, whereas in the one for LASSO I included even those where the differences were smaller.

```{r, include=FALSE, cache=TRUE}
# helper function ----------------------------------------------------------
price_diff_by_variables2 <- function(df, factor_var, dummy_var, factor_lab, dummy_lab){
  # Looking for interactions.
  # It is a function it takes 3 arguments: 1) Your dataframe,
  # 2) the factor variable (like room_type)
  # 3)the dummy variable you are interested in (like TV)

  # Process your data frame and make a new dataframe which contains the stats
  factor_var <- as.name(factor_var)
  dummy_var <- as.name(dummy_var)

  stats <- df %>%
    group_by(!!factor_var, !!dummy_var) %>%
    dplyr::summarize(Mean = mean(price, na.rm=TRUE),
                     se = sd(price)/sqrt(n()))

  stats[,2] <- lapply(stats[,2], factor)

  ggplot(stats, aes_string(colnames(stats)[1], colnames(stats)[3], fill = colnames(stats)[2]))+
    geom_bar(stat='identity', position = position_dodge(width=0.9), alpha=0.8)+
    geom_errorbar(aes(ymin=Mean-(1.96*se),ymax=Mean+(1.96*se)),
                  position=position_dodge(width = 0.9), width = 0.25)+
    ylab('Mean Price')+
    xlab(factor_lab) +
    theme(panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),
          panel.border=element_blank(),
          axis.line=element_line(),
          legend.position = "top",
          #legend.position = c(0.7, 0.9),
          legend.box = "vertical",
          legend.text = element_text(size = 5),
          legend.title = element_text(size = 5, face = "bold"),
          legend.key.size = unit(x = 0.4, units = "cm")
        )
}
```

```{r, cache=TRUE}
# check for interactions --------------------------------------------------

# check property type interactions
p1 <- price_diff_by_variables2(data, "f_property_type", "d_superhost", "Property Type", "Superhost")
p2 <- price_diff_by_variables2(data, "f_property_type", "d_profile_pic", "Property Type", "Profile Picture") 
p3 <- price_diff_by_variables2(data, "f_property_type", "d_identity_verified", "Property Type", "Identity Verified")
p4 <- price_diff_by_variables2(data, "f_property_type", "d_instant_bookable" , "Property Type", "Instant Bookable") 
p5 <- price_diff_by_variables2(data, "f_property_type", "d_wifi" , "Property Type", "Wifi") 
p6 <- price_diff_by_variables2(data, "f_property_type", "d_tv" , "Property Type", "Tv") 
p7 <- price_diff_by_variables2(data, "f_property_type", "d_refrigerator", "Property Type", "Refrigerator") 
p8 <- price_diff_by_variables2(data, "f_property_type", "d_air_conditioning" , "Property Type", "Air Conditioning")
p9 <- price_diff_by_variables2(data, "f_property_type", "d_microwave", "Property Type", "Microwave")
p10 <- price_diff_by_variables2(data, "f_property_type", "d_baby", "Property Type", "Baby Friendly")
p11 <- price_diff_by_variables2(data, "f_property_type", "d_stove", "Property Type", "Stove") 
p12 <- price_diff_by_variables2(data, "f_property_type", "d_free_parking", "Property Type", "Free Parking")
p13 <- price_diff_by_variables2(data, "f_property_type", "d_paid_parking", "Property Type", "Paid Parking") 

```

```{r, include = FALSE, cache=TRUE}
amenities <- c( "d_wifi", "d_tv", "d_refrigerator", "d_air_conditioning", "d_microwave", "d_baby", "d_stove", "d_free_parking", "d_paid_parking" )

# create lists of interactions
X_for_ols <- c('f_property_type * d_profile_pic', 'f_property_type * d_wifi','f_property_type * d_microwave', 'f_property_type * d_baby', 'f_property_type * d_stove', 'f_property_type * d_paid_parking')
X_for_lasso  <- c('f_property_type * d_superhost','f_property_type * d_identity_verified','f_property_type * d_profile_pic','f_property_type * d_air_conditioning','f_property_type * d_free_parking','f_property_type * d_refrigerator','f_property_type * d_tv', 'f_property_type * d_instant_bookable', paste0("(f_property_type) * (",paste(amenities, collapse=" + "),")"))
```

At the end of the label and feature engineering process the dataset contained 9065 observations in total on apartments that can accommodate 2-6 guests. 

## Modeling

For predicting price per night I used four different types of models:
  
  * OLS

* LASSO

* Random forest.

I proceeded by dividing the data into two parts: a training set and a holdout set. They included 80% and 20% of the observations, respectively. Then I made many lists of variables that I might use for various models. The ones for OLS and LASSO included variable levels as well as modified versions and interactions, whereas random forest just included variable levels. Using five fold cross-validation, I estimated many models with varying sets of variables or tuning parameters depending on the model. I utilized the average RMSE on the test sets as well as the RMSE on the holdout set to select the model with the best performance.

```{r, include=FALSE, cache=TRUE}
# preparation for modeling

# group variables
target_var <- 'price'

basic_vars <- c('f_property_type', 'f_neighbourhood', 'n_accommodates', 'n_bedrooms', 'n_beds', 'd_instant_bookable', 'n_bathrooms')

host_vars <- c( 'n_host_response_rate', 'flag_host_response_rate','n_host_acceptance_rate', 'flag_host_acceptance_rate', 'd_superhost', 'd_profile_pic', 'd_identity_verified', 'n_host_total_listings_count')

reviews <- c(  'n_number_of_reviews', 'flag_number_of_reviews', 'n_days_since_rv', 'flag_days_since_rv', 'n_review_scores_rating', 'flag_review_scores_rating','n_reviews_per_month', 'flag_reviews_per_month')

amenities <- c('d_wifi', 'd_tv', 'd_refrigerator', 'd_air_conditioning', 'd_microwave', 'd_baby', 'd_stove', 'd_free_parking', 'd_paid_parking')

transformed_vars <- c( 'n_beds2', 'ln_bathrooms', 'ln_number_of_reviews', 'n_days_since_rv2', 'n_host_acceptance_rate2', 'n_host_response_rate2', 'ln_host_total_listings_count', 'n_bedrooms2')

X_for_ols <- c('f_property_type * d_profile_pic', 'f_property_type * d_wifi','f_property_type * d_microwave', 'f_property_type * d_baby', 'f_property_type * d_stove', 'f_property_type * d_paid_parking')

X_for_lasso  <- c('f_property_type * d_superhost','f_property_type * d_identity_verified','f_property_type * d_profile_pic','f_property_type * d_air_conditioning','f_property_type * d_free_parking','f_property_type * d_refrigerator','f_property_type * d_tv', 'f_property_type * d_instant_bookable', paste0("(f_property_type) * (",paste(amenities, collapse=" + "),")"))

# group predictors for models

predictors_1 <- c(basic_vars)
predictors_2 <- c(basic_vars, host_vars, reviews, amenities)
predictors_3 <- c(basic_vars, host_vars, reviews, amenities, transformed_vars)
predictors_4 <- c(predictors_3, X_for_ols)
predictors_5 <- c(predictors_3, X_for_lasso)

# create holdout set
set.seed(890)

train_indices <- as.integer(createDataPartition(data$price, p = 0.8, list = FALSE))
df_train <- data[train_indices, ]
df_holdout <- data[-train_indices, ]

# set the number of folds for cross-validation
train_control <- trainControl(method = "cv",
                              number = 5,
                              verboseIter = FALSE)
```

### OLS and LASSO

In total I estimated 3 OLS models with different sets of variables. The first one contained only the levels of variables, the second one contained the levels and the transformed versions, while the last one contained interactions as well.

```{r, include=FALSE, cache=TRUE}
# simplest model
set.seed(8)
system.time({
  ols_model1 <- train(
    formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
    data = df_train,
    method = "lm",
    trControl = train_control
  )
})

ols_model_coeffs1 <-  ols_model1$finalModel$coefficients
ols_model_coeffs_df1 <- data.frame(
  "variable" = names(ols_model_coeffs1),
  "ols_coefficient" = ols_model_coeffs1
) %>%
  mutate(variable = gsub("`","",variable))

# model with transformed variables
set.seed(8)
system.time({
  ols_model2 <- train(
    formula(paste0("price ~", paste0(predictors_3, collapse = " + "))),
    data = df_train,
    method = "lm",
    trControl = train_control
  )
})

ols_model_coeffs2 <-  ols_model2$finalModel$coefficients
ols_model_coeffs_df2 <- data.frame(
  "variable" = names(ols_model_coeffs2),
  "ols_coefficient" = ols_model_coeffs2
) %>%
  mutate(variable = gsub("`","",variable))

# model with transformed variables plus interactions
set.seed(8)
system.time({
  ols_model3 <- train(
    formula(paste0("price ~", paste0(predictors_4, collapse = " + "))),
    data = df_train,
    method = "lm",
    trControl = train_control
  )
})

ols_model_coeffs3 <-  ols_model3$finalModel$coefficients
ols_model_coeffs_df3 <- data.frame(
  "variable" = names(ols_model_coeffs3),
  "ols_coefficient" = ols_model_coeffs3
) %>%
  mutate(variable = gsub("`","",variable))
```

For LASSO, I estimated two models: one with levels and transformed versions of variables plus a few interactions and one with levels and transformed versions of variables plus all the interactions I previously determined. For the lambda parameter I set the search to be between 0.01 and 1 by 0.05 differences. The value of lambda for the better model was 0.36.

```{r, include=FALSE, cache=TRUE}
# OLS with LASSO ----------------------------------------------------------

# transformed numeric variables, no interactions
set.seed(8)
system.time({
  lasso_model1 <- train(
    formula(paste0("price ~", paste0(predictors_4, collapse = " + "))),
    data = df_train,
    method = "glmnet",
    preProcess = c("center", "scale"),
    tuneGrid =  expand.grid("alpha" = 1, "lambda" = seq(0.01, 1, by = 0.05)),
    trControl = train_control
  )
})

print(lasso_model1$bestTune$lambda)

lasso_coeffs1 <- coef(
  lasso_model1$finalModel,
  lasso_model1$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  rename(lasso_coefficient = `s1`) 

lasso_coeffs_non_null1 <- lasso_coeffs1[!lasso_coeffs1$lasso_coefficient == 0,]

print(nrow(lasso_coeffs_non_null1))

# transformed numeric variables plus interactions
set.seed(8)
system.time({
  lasso_model2 <- train(
    formula(paste0("price ~", paste0(predictors_5, collapse = " + "))),
    data = df_train,
    method = "glmnet",
    preProcess = c("center", "scale"),
    tuneGrid =  expand.grid("alpha" = 1, "lambda" = seq(0.01, 1, by = 0.05)),
    trControl = train_control
  )
})

print(lasso_model2$bestTune$lambda)

lasso_coeffs2 <- coef(
  lasso_model2$finalModel,
  lasso_model2$bestTune$lambda) %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column(var = "variable") %>%
  rename(lasso_coefficient = `s1`) 

lasso_coeffs_non_null2 <- lasso_coeffs2[!lasso_coeffs2$lasso_coefficient == 0,]

print(nrow(lasso_coeffs_non_null2))
```

When comparing the coefficients of the OLS and LASSO models, I came to the conclusion that their signs were the same, but those of the LASSO models were much smaller overall.

```{r, include=FALSE, cache=TRUE}
regression_coeffs <- merge(ols_model_coeffs_df3, lasso_coeffs_non_null2, by = "variable", all=TRUE)
names(regression_coeffs) <- c('Variable', 'OLS 3', 'LASSO 2')
```

The table below gives information about the models' performance as well as the number of coefficients they had. We can observe that the best performing OLS 3 and LASSO 2 models roughly have the same number of coefficients based on both cross-validated and holdout RMSE, but they do not totally overlap. The difference in their performance is tiny.

```{r, cache=TRUE}
temp_models <-
  list("OLS 1" = ols_model1,
       "OLS 2" = ols_model2,
       "OLS 3" = ols_model3,
       "LASSO 1 (few interactions)" = lasso_model1,
       "LASSO 2 (all interactions)" = lasso_model2)

result_temp <- resamples(temp_models) %>% summary()

# get test RMSE
result_rmse <- imap(temp_models, ~{
  mean(result_temp$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")

# get holdout RMSE
result_holdout <- map(temp_models, ~{
  RMSE(predict(.x, newdata = df_holdout), df_holdout[["price"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")

# merge the two
result_combined <- cbind(result_rmse, result_holdout )

# calculate number of variables in each model
num_coefs <-  c(
  length(ols_model1$coefnames),
  length(ols_model2$coefnames),
  length(ols_model3$coefnames),
  nrow(lasso_coeffs_non_null1),
  nrow(lasso_coeffs_non_null2))

ncoefs <- as.data.frame(num_coefs, row.names = rownames(result_combined)
) %>% rename("Number of Coefficients" = "num_coefs")

# merge the three
result_combined <- cbind(ncoefs, result_rmse, result_holdout )

# print table
knitr::kable( result_combined, caption = "OLS and LASSO performance", digits = 2 ) %>% kable_styling( position = "center", latex_options = 'hold_position' )
```

Because the LASSO 2 model performed the best, I created the plot below, which displays the actual prices as well as the prices predicted by this model. We can observe that it gives better predictions for cheaper prices and somewhat underestimates prices.

```{r, cache=TRUE}
# fitted vs actual values for LASSO 2
# target variable
Ylev <- df_holdout[["price"]]

# get predicted values
predictionlev_holdout_pred <- as.data.frame(predict(lasso_model2, newdata = df_holdout))

# rename column
names(predictionlev_holdout_pred) <- "fit"

# Create data frame with the real and predicted values
d <- data.frame(ylev=Ylev, predlev=predictionlev_holdout_pred[,"fit"] )
# Check the differences
d$elev <- d$ylev - d$predlev

# Plot predicted vs price
level_vs_pred <- ggplot(data = d) +
  geom_point(aes(y=ylev, x=predlev),  size = 1,
             shape = 16, alpha = 0.7, show.legend=FALSE, na.rm=TRUE, color = "blue") +
  geom_segment(aes(x = 0, y = 0, xend = 1300, yend =1100), size=1, linetype=2, color = "red") +
  coord_cartesian(xlim = c(0, 1100), ylim = c(0, 1300)) +
  labs(y = "Price", x = "Predicted price", title = "Actual vs fitted values for the LASSO 2 model") +
  theme_bw() +
  theme( panel.grid.minor.x = element_blank(), 
         plot.title = element_text( size = 12, face = "bold", hjust = 0.5 ) )
level_vs_pred
```

### Random forest

I estimated two random forest models in total using the levels of all variables. The models differ in the parameter sets that determine the number of randomly chosen variables at each split and the minimum number of observations in the terminal nodes for each tree. Following the rule of thumb first I set the number of randomly chosen variables at each split to 6 which is around the square route of all variables. However, as the table below shows both final models produced better results when setting the parameter to a higher number. 

```{r, include=FALSE, cache=TRUE}
# simpler model
tune_grid <- expand.grid(
  .mtry = c(6, 8, 10),
  .splitrule = "variance",
  .min.node.size = c(5, 10)
)

set.seed(8)
system.time({
  rf_model_1 <- train(
    formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
    data = df_train,
    method = "ranger",
    trControl = train_control,
    tuneGrid = tune_grid,
    importance = "impurity"
  )
})

# more complex model
tune_grid <- expand.grid(
  .mtry = c(8, 10, 12),
  .splitrule = "variance",
  .min.node.size = c(5, 10, 15)
)

set.seed(8)
system.time({
  rf_model_2 <- train(
    formula(paste0("price ~", paste0(predictors_2, collapse = " + "))),
    data = df_train,
    method = "ranger",
    trControl = train_control,
    tuneGrid = tune_grid,
    importance = "impurity"
  )
})
```

```{r, cache=TRUE}
# tuning parameter choice 1
result_1 <- matrix(c(
  rf_model_1$finalModel$mtry,
  rf_model_2$finalModel$mtry,
  rf_model_1$finalModel$min.node.size,
  rf_model_2$finalModel$min.node.size
),
nrow=2, ncol=2,
dimnames = list(c("Random forest 1", "Random forest 2"),
                c("Min. number of variables","Min. node size"))
)
# print table
knitr::kable( result_1, caption = "Best hyperparameter sets for random forest models", digits = 2 ) %>% kable_styling( position = "center", latex_options = 'hold_position' )
```

The next table shows how the cross-validated RMSE changed for different hyperparameter sets in case of the second model. It is visible that there is no obvious relationship between performance and how high the parameters are set. The two best combinations are node size 15 and number of variables 8 and node size 5 and number of variables 12.

```{r, cache=TRUE}
# save results
results <- resamples(
  list(
    model_1  = rf_model_1,
    model_2  = rf_model_2
  ))

# summary table on model 2 for different hyperparameters
rf_tuning_model2 <- rf_model_2$results %>%
  dplyr::select(mtry, min.node.size, RMSE) %>%
  dplyr::rename(Nodes = min.node.size) %>%
  spread(key = mtry, value = RMSE)

# print table
knitr::kable( rf_tuning_model2, caption = "Different hyperparameter sets Random forest 2", digits = 2 ) %>% kable_styling( position = "center", latex_options = 'hold_position' )
```

To be able to decide which model is better I calculated the cross-validated RMSE-s on the test sets. We can see in the table below that Random forest 2 performs better than Random forest 1. But again just like in the case of the OLS and LASSO models the difference between the two models is relatively small.

```{r, cache=TRUE}
# RMSE of models
result_2 <- matrix(c(mean(results$values$`model_1~RMSE`),
                     mean(results$values$`model_2~RMSE`)
),
nrow=2, ncol=1,
dimnames = list(c("Random forest 1", "Random forest 2"),
                c(results$metrics[2]))
)

names(result_2) <- "CV RMSE"

# print table
knitr::kable( result_2, caption = "Performance of random forest models", digits = 2 ) %>% kable_styling( position = "center", latex_options = 'hold_position')
```

It is useful to see which factors contributed the most to the model's RMSE decrease. Because Random Forest 2 performed somewhat better, I created a variable significance plot for that model, which displayed the top ten variables that contributed the most to the reduction of RMSE in percentages. The very first variable indicates how many listings a host has in total, followed by the number of beds and the number of guests. I was expecting the neighbourhood Huangbhu district in the first 3 variables, because it is heart of the city and popular.


```{r, cache=TRUE}
# variable importance plot for random forest 2
rf_model_2_var_imp <- importance(rf_model_2$finalModel)/1000
rf_model_2_var_imp_df <-
  data.frame(varname = names(rf_model_2_var_imp),imp = rf_model_2_var_imp) %>%
  mutate(varname = gsub("f_neighbourhood", "Neighbourhood:", varname) ) %>%
  mutate(varname = gsub("f_room_type", "Room type:", varname) ) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))

rf_model_2_var_imp_plot_b <- ggplot(rf_model_2_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color="red", size=1) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color="blue", size=1) +
  ylab("Importance") +
  xlab("Variable Name") +
  labs( title= "Variable importance for Random forest 2 (top 10 variables)") +
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw() +
  theme( panel.grid.minor.x = element_blank(), 
         plot.title = element_text( size = 12, face = "bold", hjust = 0.5 ) )
rf_model_2_var_imp_plot_b
```

Another method for producing the variable significance plot is to group the various sorts of variables. From the factors I utilized, I created four major groupings. The first is made up of fundamental variables that characterize the apartment's qualities, the second of which is host information, the third of which is information regarding reviews, and the fourth of which is made up of amenities dummies. The graph below depicts their significance for the Random Forest 2 model. It may be inferred that the host information and fundamental apartment parameters are the most relevant and contribute for around 60-70 percent of the RMSE decrease.

```{r, include=FALSE, cache=TRUE}
# grouped variable importance
amenities <- c( "d_wifi1", "d_tv1", "d_refrigerator1", "d_air_conditioning1", "d_microwave1", "d_baby1", "d_stove1", "d_free_parking1", "d_paid_parking1" )
```

```{r, cache=TRUE}
rf_model_var_imp_df <- rf_model_2_var_imp_df %>% mutate(
  group2 = ifelse(varname %in% amenities, 'amenities',
                  ifelse(varname %in% basic_vars, 'basic variables',
                         ifelse(varname %in% reviews, 'reviews', 'host info'))))
rf_model_var_imp_grouped2 <- rf_model_var_imp_df %>%  group_by(group2) %>% summarise(group_imp_sum = sum(imp_percentage)) %>%  arrange(desc(group_imp_sum))
rf_model_var_imp_grouped2_plot <-
  ggplot(rf_model_var_imp_grouped2, aes(x=reorder(group2, group_imp_sum), y=group_imp_sum)) +
  geom_point(color="red", size=1) +
  geom_segment(aes(x=group2,xend=group2,y=0,yend=group_imp_sum), color="blue", size=1) +
  ylab("Importance") +   xlab("Variable Name") +
  coord_flip() +
  # expand=c(0,0),
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw() +
  labs( title='Grouped variable importance plot for Random Forest 2') +
  theme( panel.grid.minor.x = element_blank(), 
         plot.title = element_text( size = 12, face = "bold", hjust = 0.5 ) )

rf_model_var_imp_grouped2_plot
```

### Model selection

After running different types, I choose the best results from each method. I described their cross-validated RMSEs as well as their RMSEs determined on the holdout set in the table below. According to these data, the random forest model outperformed the LASSO and OLS models. However, the pricing plan I would recommend for the firm would be determined by their choices. If they want to see the relationship between specific explanatory factors and the target variable and have coefficients, I would recommend using either the LASSO model or the OLS because their performance is fairly close. Otherwise, I would suggest using the random forest model since that one has the best prediction performance.

```{r, cache=TRUE}
# Model selection ---------------------------------------------------------

final_models <-
  list("OLS 3" = ols_model3,
       "LASSO (all interactions)" = lasso_model2,
       "Random forest 2" = rf_model_2)

results <- resamples(final_models) %>% summary()

# evaluate final models on holdout set
final_rmse <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")

final_holdout <- map(final_models, ~{
  RMSE(predict(.x, newdata = df_holdout), df_holdout[["price"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")

final_combined <- cbind(final_rmse, final_holdout)

# print table
knitr::kable( final_combined, caption = "Model performance comparison", digits = 2 ) %>% kable_styling( position = "center", latex_options = 'hold_position')
```



